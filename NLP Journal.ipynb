{"metadata":{"kernelspec":{"name":"python","display_name":"Python (Pyodide)","language":"python"},"language_info":{"codemirror_mode":{"name":"python","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8"},"colab":{"provenance":[],"collapsed_sections":["d089ce94-3005-4291-94fa-2695768e282b","6a9c2eed-6cbb-45e2-bf26-18441c08ecde","eq4WbUTjlTsX","PUKCaXaDcepV","-m4D1X0nGClo"]}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d089ce94-3005-4291-94fa-2695768e282b","cell_type":"markdown","source":["## Practical 1\n","#### Basic Text Processing operation on text document"],"metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"d089ce94-3005-4291-94fa-2695768e282b"}},{"id":"e8a8f182-7557-4e97-9fe8-5e843792dc18","cell_type":"code","source":["for line in open(\"/content/data.txt\"):\n","    for word in line.split():\n","        if word.endswith(\"ing\"):\n","            print(word)\n","            print(len(word))"],"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"e8a8f182-7557-4e97-9fe8-5e843792dc18","executionInfo":{"status":"error","timestamp":1741861305962,"user_tz":-330,"elapsed":79,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"88c63037-6b08-45cf-bffb-d4d40850499c"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/data.txt'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-8f1f97bc7c44>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/data.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data.txt'"]}],"execution_count":null},{"id":"619d619e-811b-41c5-aa61-c7eadfd58bc3","cell_type":"code","source":["import re\n","\n","data=\"The biggest 5 Animals are 1.Elephant 2.Girrafe 3.Tiger 4.Lion 5.Cheetah\"\n","\n","result = re.sub(r\"\\d+\", '', data)\n","#sub is the function to replace the words\n","# /d means all the digits in the data.txt\n","\n","print(result)"],"metadata":{"trusted":true,"id":"619d619e-811b-41c5-aa61-c7eadfd58bc3"},"outputs":[],"execution_count":null},{"id":"4af9221e-8cf1-420a-823a-0054b58a7263","cell_type":"code","source":["def punctuations(data):\n","    text=data\n","    text=text.replace(\"nt\",\"not\")\n","    text=text.replace(\"'s\",\" is\")\n","    text=text.replace(\"'re\",\" are\")\n","    text=text.replace(\"'ll\",\" will\")\n","    text=text.replace(\"doin\",\"doing\")\n","    return text\n","\n","s=\"How's my team doin,you're supposed to be nt losing\"\n","returned_data=punctuations(s)\n","print(returned_data)"],"metadata":{"trusted":true,"id":"4af9221e-8cf1-420a-823a-0054b58a7263"},"outputs":[],"execution_count":null},{"id":"6a9c2eed-6cbb-45e2-bf26-18441c08ecde","cell_type":"markdown","source":["## Practical 2\n","#### Tokenization and Stemming in Natural Language Processing"],"metadata":{"id":"6a9c2eed-6cbb-45e2-bf26-18441c08ecde"}},{"id":"6378108c-13a6-4422-a706-dfb31fab9aef","cell_type":"code","source":["import nltk\n","nltk.download('punkt_tab')\n","\n","data = \"My name is Dattaram Santosh Kolte. I am 21 years old. I live in Ghansoli.\"\n","# splits the words in the text data\n","tokens = nltk.word_tokenize(data)\n","print(tokens)\n","\n","# splits the sentences in the text data\n","tokens = nltk.sent_tokenize(data)\n","print(tokens)"],"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"6378108c-13a6-4422-a706-dfb31fab9aef","executionInfo":{"status":"ok","timestamp":1742411867854,"user_tz":-330,"elapsed":319,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"98b14ea5-59cc-4d09-b4f2-c04257e4f351"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["['My', 'name', 'is', 'Dattaram', 'Santosh', 'Kolte', '.', 'I', 'am', '21', 'years', 'old', '.', 'I', 'live', 'in', 'Ghansoli', '.']\n","['My name is Dattaram Santosh Kolte.', 'I am 21 years old.', 'I live in Ghansoli.']\n"]}],"execution_count":null},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","\n","ps = PorterStemmer()\n","\n","print(ps.stem(\"Socks\"))\n","\n","words = [\"program\", \"programs\", \"programer\", \"programing\", \"programers\",\"Studies\",\"Happiness\"]\n","\n","for w in words:\n","    print(w, \" : \", ps.stem(w))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLUJxpcknOHl","executionInfo":{"status":"ok","timestamp":1742411876935,"user_tz":-330,"elapsed":19,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"9a639a50-82b0-4feb-d483-98a7c675e94c"},"id":"KLUJxpcknOHl","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sock\n","program  :  program\n","programs  :  program\n","programer  :  program\n","programing  :  program\n","programers  :  program\n","Studies  :  studi\n","Happiness  :  happi\n"]}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","nltk.download('wordnet')\n","\n","lm = WordNetLemmatizer()\n","\n","print(\"Socks :\",lm.lemmatize(\"socks\"))\n","print(\"Better\",lm.lemmatize(\"better\",pos=\"a\"))\n","print(\"Am\",lm.lemmatize(\"am\",pos=\"v\"))\n","\n","words = [\"cats\",\"cacti\",\"radii\",\"feet\",\"speech\",'runner',\"studies\",\"peas\",\"salaries\",\"corpora\"]\n","\n","for w in words:\n","    print(w,\":\",lm.lemmatize(w))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hm13_zFAoAuV","executionInfo":{"status":"ok","timestamp":1742411978954,"user_tz":-330,"elapsed":12,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"322687ea-cf14-425d-df8e-248f7eeab5d3"},"id":"Hm13_zFAoAuV","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Socks : sock\n","Better good\n","Am be\n","cats : cat\n","cacti : cactus\n","radii : radius\n","feet : foot\n","speech : speech\n","runner : runner\n","studies : study\n","peas : pea\n","salaries : salary\n","corpora : corpus\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["## Practical 3\n","#### Removal of Stopwords"],"metadata":{"id":"eq4WbUTjlTsX"},"id":"eq4WbUTjlTsX"},{"cell_type":"code","source":["from nltk.corpus import stopwords as sw\n","import nltk\n","nltk.download('stopwords')\n","\n","stopwords = set(sw.words('english'))\n","print(stopwords)\n","\n","data=\"All work and no play makes jack a dull boy\"\n","tokens = nltk.word_tokenize(data)\n","data_without_stopwords = []\n","\n","for word in tokens:\n","  if word not in stopwords:\n","    data_without_stopwords.append(word)\n","\n","print(data_without_stopwords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOeXBCq4pv72","executionInfo":{"status":"ok","timestamp":1742412009551,"user_tz":-330,"elapsed":88,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"0b4dc58c-62c9-4dbb-ec54-c0723a55bda6"},"id":"iOeXBCq4pv72","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'with', 'whom', 'couldn', 'does', 'being', \"mustn't\", \"shouldn't\", \"you've\", 'itself', 'd', 'out', 'they', 'below', 'doesn', \"aren't\", 'same', 'only', 'each', 'are', 'as', 'wouldn', 'weren', 'ourselves', 'this', 'were', 'too', \"it's\", \"they've\", 'not', 'theirs', \"she's\", 'again', 'more', 'or', 'while', \"couldn't\", 'haven', 'no', 'should', 'on', \"doesn't\", 'what', 'from', 'had', \"hasn't\", 'did', 't', 'hasn', 'has', 'our', 'shouldn', 'it', 'some', 'during', 'if', 'off', 'so', 'am', 'm', 'have', 'having', 'wasn', 'when', 'isn', 'such', 'against', \"we've\", \"mightn't\", 'aren', 'was', 'mustn', 'down', \"won't\", 'into', 'under', \"i'll\", 'ain', \"should've\", 'you', 'who', 'most', \"it'll\", 'about', 'can', 'won', 'doing', 'himself', \"isn't\", 'mightn', 'nor', 'he', 'at', 'my', 'o', 'them', \"haven't\", 'all', \"i'd\", \"he'll\", 'over', 'hadn', 'further', 'those', 'didn', 'above', 'before', \"hadn't\", 'him', 'after', 'is', \"wasn't\", 'here', 'where', 'both', \"didn't\", 'me', 'be', \"don't\", \"that'll\", 'needn', 'll', 'yours', 'shan', 'to', 'which', \"wouldn't\", 'but', 'because', 'by', 'these', \"you're\", 'will', 'her', 'then', 'yourself', 'any', 'few', 'yourselves', \"we're\", 'y', 'she', 'your', 'an', 'do', 'and', \"shan't\", 'that', 'myself', 's', \"they're\", \"weren't\", 'themselves', 'other', 'through', 'ours', \"she'd\", 'between', \"he'd\", 'than', 'how', 'hers', \"i'm\", \"i've\", 'once', 'up', \"we'd\", 'there', \"they'll\", 'why', \"he's\", 'in', \"they'd\", \"you'd\", 'been', 'don', 'just', 're', 'the', 'we', 'now', 'own', \"we'll\", \"needn't\", 'a', 'ma', 'of', \"she'll\", 'their', \"it'd\", 'until', 'for', \"you'll\", 've', 'herself', 'very', 'its', 'i', 'his'}\n","['All', 'work', 'play', 'makes', 'jack', 'dull', 'boy']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["## Practical 4\n","#### Implementation of POS Tag"],"metadata":{"id":"PUKCaXaDcepV"},"id":"PUKCaXaDcepV"},{"cell_type":"code","source":["import spacy\n","\n","nlp = spacy.load('en_core_web_sm')\n","\n","doc = nlp(\"Don't be afraid to give up the good to go for the grea\")\n","\n","POS_count = doc.count_by(spacy.attrs.POS)\n","print((POS_count))\n","\n","for k,v in sorted(POS_count.items()):\n","  print(f\"{k}, {doc.vocab[k].text} : {v}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741861829679,"user_tz":-330,"elapsed":9937,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"ce732131-d328-4029-ebc9-93177f9f560b","id":"HrRDYM45cepW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{87: 2, 94: 3, 84: 1, 100: 2, 85: 2, 90: 2, 92: 2}\n","84, ADJ : 1\n","85, ADP : 2\n","87, AUX : 2\n","90, DET : 2\n","92, NOUN : 2\n","94, PART : 3\n","100, VERB : 2\n"]}],"id":"HrRDYM45cepW"},{"cell_type":"code","source":["import spacy\n","from spacy import displacy\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(\"This is my school\")\n","\n","POS_count = doc.count_by(spacy.attrs.POS)\n","for k,v in sorted(POS_count.items()):\n","  print(f\"{k}, {doc.vocab[k].text} : {v}\")\n","\n","options = {\n","    \"color\": \"blue\",\n","    \"bg\": \"pink\",\n","    \"compact\": True,\n","    \"distance\": 100,\n","    \"arrow_stroke\": 2,\n","}\n","displacy.render(doc,style='ent',options=option)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"lZE_EZ1Sg1wD","executionInfo":{"status":"ok","timestamp":1741863524617,"user_tz":-330,"elapsed":673,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"e5b086e4-bc77-473c-83b9-ad56308a7703"},"id":"lZE_EZ1Sg1wD","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["87, AUX : 1\n","92, NOUN : 1\n","95, PRON : 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/spacy/displacy/__init__.py:213: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n","  warnings.warn(Warnings.W006)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This is my school</div></span>"]},"metadata":{}}]},{"cell_type":"code","source":["import nltk\n","from nltk import pos_tag, word_tokenize\n","from nltk.draw import tree\n","\n","# Sample text\n","text = \"This is my school\"\n","\n","# Tokenization\n","tokens = word_tokenize(text) #list of tokens\n","print(tokens)\n","\n","# Part-of-Speech Tagging\n","pos_tags = pos_tag(tokens) #returns a list of tupels\n","print(pos_tags)\n","# Display POS tags\n","for word, tag in pos_tags:\n","    print(f\"{word} : {tag}\")\n","\n","# Drawing the POS dependency tree\n","tree_obj = nltk.Tree('Sentence', [(word, tag) for word, tag in pos_tags])\n","tree_obj.pretty_print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmT03zrp9mmI","executionInfo":{"status":"ok","timestamp":1741863290277,"user_tz":-330,"elapsed":9,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"97f06c50-a502-421c-f018-c3679a761fe9"},"id":"wmT03zrp9mmI","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['This', 'is', 'my', 'school']\n","[('This', 'DT'), ('is', 'VBZ'), ('my', 'PRP$'), ('school', 'NN')]\n","This : DT\n","is : VBZ\n","my : PRP$\n","school : NN\n","        Sentence                  \n","    _______|_________________      \n","This/DT  is/VBZ  my/PRP$ school/NN\n","\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.chunk import ne_chunk\n","nltk.download(\"punkt_tab\")\n","nltk.download(\"averaged_perceptron_tagger_eng\")\n","nltk.download(\"maxent_ne_chunker_tab\")\n","nltk.download(\"words\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PYhkyPQGL6k","executionInfo":{"status":"ok","timestamp":1742467800645,"user_tz":-330,"elapsed":8,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"954903c5-f5bb-4347-d640-1354047672c7"},"id":"_PYhkyPQGL6k","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package maxent_ne_chunker_tab to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["## Practical 5\n","#### Write a program to implement the N-gram model."],"metadata":{"id":"ThEr324IVkbu"},"id":"ThEr324IVkbu"},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt_tab')\n","\n","from nltk.util import ngrams\n","from nltk.tokenize import word_tokenize\n","data=\"The little boy ran away\"\n","#tokenize the text\n","token=nltk.word_tokenize(data)\n","Ngram=ngrams(token,3)\n","print(\"Trigram\")\n","for gram in Ngram: print(gram)\n","\n","#BIGRAM\n","Ngram=ngrams(token,2)\n","print(\"\\nBigram\")\n","for gram in Ngram: print(gram)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWTU9eQZV7D8","executionInfo":{"status":"ok","timestamp":1747671693745,"user_tz":-330,"elapsed":11,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"225c75b8-efbd-41e0-c3e8-581355507649"},"id":"xWTU9eQZV7D8","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trigram\n","('The', 'little', 'boy')\n","('little', 'boy', 'ran')\n","('boy', 'ran', 'away')\n","\n","Bigram\n","('The', 'little')\n","('little', 'boy')\n","('boy', 'ran')\n","('ran', 'away')\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["# Practical No 7"],"metadata":{"id":"-m4D1X0nGClo"},"id":"-m4D1X0nGClo"},{"cell_type":"code","source":["# Tokenize the data\n","text = \"My name is Dattaram Santosh Kolte. I born in Ghansoli. I went to Harvard University>\"\n","tokens = nltk.word_tokenize(text)\n","sent_tokens = nltk.sent_tokenize(text)\n","print(tokens)\n","print(sent_tokens)\n","\n","# PoS Tagging\n","pos_tagged = nltk.pos_tag(tokens)\n","print(pos_tagged)\n","for i in pos_tagged:\n","  print(i[0], \":\", i[1])\n","\n","# Entity tagging\n","entities = ne_chunk(pos_tagged)\n","print(entities)\n","entities.draw()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":983},"id":"6h_t0v8ZGYPC","executionInfo":{"status":"error","timestamp":1742467801210,"user_tz":-330,"elapsed":561,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"a2ae3e7a-2eda-4ade-be21-b0014b8cc743"},"id":"6h_t0v8ZGYPC","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['My', 'name', 'is', 'Dattaram', 'Santosh', 'Kolte', '.', 'I', 'born', 'in', 'Ghansoli', '.', 'I', 'went', 'to', 'Harvard', 'University', '>']\n","['My name is Dattaram Santosh Kolte.', 'I born in Ghansoli.', 'I went to Harvard University>']\n","[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Dattaram', 'NNP'), ('Santosh', 'NNP'), ('Kolte', 'NNP'), ('.', '.'), ('I', 'PRP'), ('born', 'VBP'), ('in', 'IN'), ('Ghansoli', 'NNP'), ('.', '.'), ('I', 'PRP'), ('went', 'VBD'), ('to', 'TO'), ('Harvard', 'NNP'), ('University', 'NNP'), ('>', 'NNP')]\n","My : PRP$\n","name : NN\n","is : VBZ\n","Dattaram : NNP\n","Santosh : NNP\n","Kolte : NNP\n",". : .\n","I : PRP\n","born : VBP\n","in : IN\n","Ghansoli : NNP\n",". : .\n","I : PRP\n","went : VBD\n","to : TO\n","Harvard : NNP\n","University : NNP\n","> : NNP\n","(S\n","  My/PRP$\n","  name/NN\n","  is/VBZ\n","  (PERSON Dattaram/NNP Santosh/NNP Kolte/NNP)\n","  ./.\n","  I/PRP\n","  born/VBP\n","  in/IN\n","  (GPE Ghansoli/NNP)\n","  ./.\n","  I/PRP\n","  went/VBD\n","  to/TO\n","  (ORGANIZATION Harvard/NNP University/NNP)\n","  >/NNP)\n"]},{"output_type":"error","ename":"TclError","evalue":"no display name and no $DISPLAY environment variable","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-1e3c13480099>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mentities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mne_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tree/tree.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0mdraw_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36mdraw_trees\u001b[0;34m(*trees)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \"\"\"\n\u001b[0;32m-> 1008\u001b[0;31m     \u001b[0mTreeView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *trees)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NLTK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<Control-x>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2324\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"]}]},{"cell_type":"code","source":[],"metadata":{"id":"vLo1AVrAHS_i"},"id":"vLo1AVrAHS_i","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install transformers\n","# !pip install torch\n","from transformers import pipeline\n","\n","def summarize_text(text, max_length=150, min_length=50):\n","    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n","    summary = summarizer(text, max_length=max_length, min_length=min_length,\n","do_sample=False)\n","    return summary[0]['summary_text']\n","\n","# Example usage\n","long_text = \"\"\" Human communication has come a long way since ancient civilizations first developed methods to share information. From rudimentary signals to complex digital conversations, the transformation of how people connect is a testament to both innovation and necessity.In ancient times, early humans relied on basic forms of communication such as cave paintings, symbols, and hand gestures. As societies grew, more structured methods emerged, including the use of smoke signals and drum beats to transmit simple messages over long distances. These early techniques were effective in specific contexts but lacked depth and complexity.The invention of writing marked a significant leap forward. The earliest forms of written communication appeared around 3100 BCE in Mesopotamia, where the Sumerians developed cuneiform scripts to record trade transactions and historical events. Similarly, Egyptian hieroglyphs offered a more visual approach to documenting information. Writing enabled people to store knowledge, share stories, and communicate across time and space.\"\"\"\n","\n","summary = summarize_text(long_text)\n","print(\"Abstractive text summarization\")\n","print(\"Original text length:\", len(long_text))\n","print(\"Summary length:\", len(summary))\n","print(\"\\nSummary:\")\n","print(summary)\n"],"metadata":{"id":"2aKFovX6HqPX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747685357830,"user_tz":-330,"elapsed":18941,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"e5a4bf92-e9ad-46d7-e892-f5642c2197b1"},"id":"2aKFovX6HqPX","execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":["Abstractive text summarization\n","Original text length: 1059\n","Summary length: 332\n","\n","Summary:\n","In ancient times, early humans relied on basic forms of communication such as cave paintings, symbols, and hand gestures. As societies grew, more structured methods emerged, including the use of smoke signals and drum beats to transmit simple messages over long distances. The invention of writing marked a significant leap forward.\n"]}]},{"cell_type":"code","source":["!pip install sumy\n","import nltk\n","nltk.download('punkt_tab')\n","\n","from sumy.parsers.plaintext import PlaintextParser\n","from sumy.nlp.tokenizers import Tokenizer\n","from sumy.summarizers.lex_rank import LexRankSummarizer\n","\n","# Sample text\n","text = \"\"\"Human communication has come a long way since ancient civilizations first developed methods to share information. From rudimentary signals to complex digital conversations, the transformation of how people connect is a testament to both innovation and necessity.In ancient times, early humans relied on basic forms of communication such as cave paintings, symbols, and hand gestures. As societies grew, more structured methods emerged, including the use of smoke signals and drum beats to transmit simple messages over long distances. These early techniques were effective in specific contexts but lacked depth and complexity.The invention of writing marked a significant leap forward. The earliest forms of written communication appeared around 3100 BCE in Mesopotamia, where the Sumerians developed cuneiform scripts to record trade transactions and historical events. Similarly, Egyptian hieroglyphs offered a more visual approach to documenting information. Writing enabled people to store knowledge, share stories, and communicate across time and space.\"\"\"\n","\n","# Create parser and summarizer\n","parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n","summarizer = LexRankSummarizer()\n","\n","# Get top 2 sentences as summary\n","summary = summarizer(parser.document, sentences_count=2)\n","\n","# Print results\n","summary_text = \" \".join(str(sentence) for sentence in summary)\n","print(\"131 Sakib Tamboli\")\n","print(\"Extractive text summarization\")\n","print(\"\\nOriginal text length:\", len(text))\n","print(\"Summary length:\", len(summary_text))\n","print(\"Summary:\", summary_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gLYiAiEeLLSh","executionInfo":{"status":"ok","timestamp":1747685566840,"user_tz":-330,"elapsed":4162,"user":{"displayName":"Dattaram Kolte","userId":"01927237721488350495"}},"outputId":"c0aed095-06e7-444d-dc6c-64db9ec5e0dc"},"id":"gLYiAiEeLLSh","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sumy in /usr/local/lib/python3.11/dist-packages (0.11.0)\n","Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from sumy) (0.6.2)\n","Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.11/dist-packages (from sumy) (0.1.20)\n","Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from sumy) (2.32.3)\n","Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.11/dist-packages (from sumy) (24.6.1)\n","Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from sumy) (3.9.1)\n","Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n","Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.4.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (8.2.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (1.5.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (4.67.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2025.4.26)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["131 Sakib Tamboli\n","Extractive text summarization\n","\n","Original text length: 1058\n","Summary length: 383\n","Summary: Human communication has come a long way since ancient civilizations first developed methods to share information. From rudimentary signals to complex digital conversations, the transformation of how people connect is a testament to both innovation and necessity.In ancient times, early humans relied on basic forms of communication such as cave paintings, symbols, and hand gestures.\n"]}]}]}